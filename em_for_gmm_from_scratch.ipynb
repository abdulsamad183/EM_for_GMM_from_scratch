{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# EM Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Step-1: Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(data,K):\n",
    "    \n",
    "  d=data.shape[1] # dimension of data\n",
    "\n",
    "  # mean initialization  \n",
    "  pick_means=np.random.randint(0,data.shape[0],K)\n",
    "  means=data[pick_means,:]\n",
    "  means=np.transpose(means)\n",
    "    \n",
    "  # covariance matrix initialization  \n",
    "  Covariance=np.zeros((d,d,K))\n",
    "  for i in range(K):\n",
    "    Covariance[:,:,i]=np.eye(d)*np.max(data,axis=None)    \n",
    "\n",
    "  #mixing coefficients  \n",
    "  proportions=np.ones((K,1))/K\n",
    "  theta=[means,Covariance,proportions]\n",
    "\n",
    "  return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Step 2: Expectation stage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "$$\\gamma_{ik}=\\frac{w_{k}P(x_{i}|\\Phi_{k})}{\\sum_{k=1}^{K}w_{k}P(x_{i}|\\Phi_{k})}$$\n",
    "where,\n",
    "$$\\Phi_{k}=\\{\\mu_{k},\\Sigma_{k}\\}$$\n",
    "$$\\theta_{k}=\\{\\Phi_{k},w_{k}\\}$$\n",
    "$$w_{k}=\\frac{N_{k}}{N}$$\n",
    "$$N_{k}=\\sum_{i=1}^{N}\\gamma_{ik}$$\n",
    "$$P(x_{i}|\\Phi_{k})=\\frac{1}{(2 \\pi)^{d/2}|\\Sigma_{k}|^{1/2}}e^{-(x_{i}-\\mu_{k})^{T}\\Sigma_{k}^{-1}(x_{i}-\\mu_{k})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "def E_Step_GMM(data,K,theta):\n",
    "    \n",
    "    means=theta[0]\n",
    "    Covariance=theta[1]\n",
    "    proportions=theta[2]\n",
    "    \n",
    "    responsibility=np.zeros((len(data),K))#Computing responsibility coefficients of each point for each cluster.\n",
    "    \n",
    "    for i in range(K): #Running for K number of time i.e., Number of clusters\n",
    "        itr=0   # increase w.r.t datapoint \n",
    "        \n",
    "        for x in data:\n",
    "            \n",
    "            normalising=0 ## Denomintor\n",
    "\n",
    "            # Compute probability of xj for cluster i \n",
    "            N_xn=multivariate_normal.pdf(x,mean=means[:,i], cov=Covariance[:,:,i])\n",
    "            # # only to avoid \n",
    "            # if N_xn<10**(-20):\n",
    "            #   N_xn=10**(-20)\n",
    "            responsibility[itr][i]=proportions[i]*N_xn\n",
    "            \n",
    "            for j in range(K):\n",
    "                normalising+=proportions[j]*(multivariate_normal.pdf(x,mean=means[:,j], cov=Covariance[:,:,j])+10**(-20))\n",
    "                \n",
    "            responsibility[itr][i]=responsibility[itr][i]/normalising\n",
    "            \n",
    "            itr+=1\n",
    "\n",
    "    \n",
    "    return responsibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Step-3: Maximization Stage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) $w_{k}=\\frac{N_{k}}{N}$, where  $N_{k}=\\sum_{i=1}^{N}\\gamma_{ik}$\n",
    "\n",
    "b) $\\mu_{k}=\\frac{\\sum_{i=1}^{N}\\gamma_{ik}x_{i}}{N_{k}}$\n",
    "\n",
    "c) $\\Sigma_{k}=\\frac{\\sum_{i=1}^{N}\\gamma_{ik}(x_{i}-\\mu_{k})(x_{i}-\\mu_{k})^{T}}{N_{k}}$\n",
    "\n",
    "Objective function(maximized through iteration):\n",
    "$$L(\\theta)=\\sum_{i=1}^{N}log\\sum_{k=1}^{K}w_{k}P(x_{i}|\\Phi_{k})$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_Step_GMM(data,responsibility):\n",
    "    \n",
    "    [N,K]=np.shape(responsibility) #N is number of data points\n",
    "    d=data.shape[1]\n",
    "    Nk=np.sum(responsibility,axis=0)\n",
    "    proportions=Nk/N\n",
    "    means=np.zeros((K,d))  \n",
    "    \n",
    "    for k in range(K):\n",
    "        temp1=data\n",
    "        temp2=responsibility[:,k]\n",
    "        temp=temp1*temp2[:,None] #multiplying a vector with multiple columns\n",
    "        means[k]=(1/Nk[k])*np.sum(temp,axis=0)  \n",
    "    means=np.transpose(means)\n",
    "    \n",
    "    Covariance=np.zeros((d,d,K))        \n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            temp1=data[n,:]-means[:,k]\n",
    "            temp2=np.outer(temp1,np.transpose(temp1)) # vector outer product\n",
    "            temp=responsibility[n,k]*temp2\n",
    "            Covariance[:,:,k]+=temp\n",
    "        Covariance[:,:,k]=(1/Nk[k])*Covariance[:,:,k]\n",
    "\n",
    "    \n",
    "    theta=[means,Covariance,proportions]\n",
    "    \n",
    "    Likelihood=0\n",
    "    log_likelihood=0\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            Likelihood+=proportions[k]*(multivariate_normal.pdf(data[n,:],mean=means[:,k], cov=Covariance[:,:,k]))\n",
    "        log_likelihood+=np.log(Likelihood)  \n",
    "        \n",
    "    return theta, log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyaISKY3dfWy",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_BSipJB1AQHG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data  :  (120, 4) (120,)\n",
      "Testing Data   :  (30, 4) (30,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris_data_file = open('iris/iris.data','r')\n",
    "lines = iris_data_file.readlines()[:-1]\n",
    "iris_data = []\n",
    "for i in lines:\n",
    "    try:\n",
    "        point = i[:-2].split(',')\n",
    "        if point[-1] == 'Iris-setos':\n",
    "            label = 0\n",
    "        elif point[-1] == 'Iris-versicolo':\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 2\n",
    "        a=float(point[0])\n",
    "        b=float(point[1])\n",
    "        c=float(point[2])\n",
    "        d=float(point[3])\n",
    "        one_point = [a,b,c,d,label]\n",
    "        iris_data.append(one_point)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "iris_data = np.array(iris_data)\n",
    "X = iris_data[:,:-1]\n",
    "y = iris_data[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20, random_state=42)\n",
    "print('Training Data  : ',X_train.shape,y_train.shape)\n",
    "print('Testing Data   : ',X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Without Inbuilt Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 2 1 0 0 0 2 1 1 0 0 1 2 2 1 2 1 2 1 0 2 1 0 0 0 1 2 0 0 0 1 0 1\n",
      " 2 0 1 2 0 2 2 1 1 2 1 0 1 2 0 0 1 1 0 2 0 0 2 1 2 2 2 2 1 0 0 2 2 0 0 0 2\n",
      " 2 0 2 2 0 1 1 2 1 2 0 2 1 2 1 1 1 0 1 1 0 1 2 2 0 1 2 2 0 2 0 1 2 2 1 2 1\n",
      " 1 2 2 0 1 2 0 1 2]\n",
      "[0. 0. 1. 0. 0. 2. 1. 0. 0. 0. 2. 1. 1. 0. 0. 1. 2. 2. 1. 2. 1. 2. 1. 0.\n",
      " 2. 1. 0. 0. 0. 1. 2. 0. 0. 0. 1. 0. 1. 2. 0. 1. 2. 0. 2. 2. 1. 1. 2. 1.\n",
      " 0. 1. 2. 0. 0. 1. 1. 0. 2. 0. 0. 1. 1. 2. 1. 2. 2. 1. 0. 0. 2. 2. 0. 0.\n",
      " 0. 1. 2. 0. 2. 2. 0. 1. 1. 2. 1. 2. 0. 2. 1. 2. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 2. 2. 0. 1. 2. 2. 0. 2. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 0. 1. 2. 0. 1. 2.]\n",
      "Accuracy =  0.9185298404481175\n",
      "Number of iterations needed for convergence: 82\n",
      "Converged log-likelihood value: 438.328693811361\n"
     ]
    }
   ],
   "source": [
    "log_l=[]\n",
    "Itr=250\n",
    "eps=10**(-14)  # for threshold\n",
    "K = 3   # no. of clusters\n",
    "# data=(X_train-(np.mean(X_train,axis=0)))/(np.std(X_train,axis=0)) # data normalization\n",
    "data = X_train\n",
    "theta=initialization(data,K)\n",
    "iter=0\n",
    "for n in range(Itr):\n",
    "  responsibility=E_Step_GMM(data,K,theta)\n",
    "  cluster_label=np.argmax(responsibility,axis=1) #Label Points\n",
    "  theta,log_likhd=M_Step_GMM(data,responsibility)\n",
    "  log_l.append(log_likhd)\n",
    "  Cents=theta[0].T\n",
    "  if n>2:\n",
    "    if abs(log_l[n]-log_l[n-1])<eps:\n",
    "      iter=n\n",
    "      break\n",
    "\n",
    "from sklearn import metrics\n",
    "pred_lab=cluster_label\n",
    "print(pred_lab)\n",
    "print(y_train)\n",
    "print('Accuracy = ',metrics.homogeneity_score(pred_lab,y_train))\n",
    "\n",
    "print(f\"Number of iterations needed for convergence: {iter}\")\n",
    "print(f\"Converged log-likelihood value: {log_l[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means with Manual Calculation :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.99      , 3.44      , 1.4525    , 0.2425    ],\n",
       "       [5.90755446, 2.7688834 , 4.18873027, 1.29857729],\n",
       "       [6.49946976, 2.95408136, 5.47504177, 1.97176261]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Means with Manual Calculation :\")\n",
    "theta[0].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### With Using Inbuilt Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :  0.9266186789173232\n",
      "Testing Accuracy :  0.8989818741826271\n",
      "[[6.50442412 2.95387167 5.48252847 1.97542369]\n",
      " [4.99       3.44       1.4525     0.2425    ]\n",
      " [5.90948294 2.77139193 4.19647176 1.30290704]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "gmm = GaussianMixture(n_components=3)\n",
    "gmm.fit(X_train)\n",
    "\n",
    "\n",
    "labelss = gmm.predict(X_train)\n",
    "accc = adjusted_rand_score(labelss,y_train)\n",
    "print(\"Training Accuracy : \",accc)\n",
    "\n",
    "\n",
    "labels = gmm.predict(X_test)\n",
    "acc = adjusted_rand_score(labels,y_test)\n",
    "\n",
    "\n",
    "num_iterations = gmm.n_iter_\n",
    "centers = gmm.means_\n",
    "print(\"Testing Accuracy : \",acc)\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
